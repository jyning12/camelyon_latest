{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 千兆病理图像癌细胞转移检测\n",
    "## Detecting Cancer Metastases on Gigapixel Pathology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openslide\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "\n",
    "# 读取包含有肿瘤区域的大图（全切片病理图像）\n",
    "origin_images_path = \"/atlas/home/zwpeng/paper_rebuild/camelyon/train/tumor/origin_images/Tumor_005.tif\"\n",
    "origin_slide = openslide.open_slide(origin_images_path)\n",
    "\n",
    "# 读取该肿瘤区域的标注图\n",
    "annotation_images_path = \"/atlas/home/zwpeng/paper_rebuild/camelyon/train/tumor/annotation_images/Tumor_005_Mask.tif\"\n",
    "mask_slide = openslide.open_slide(annotation_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# origin_slide.level_count,origin_slide.level_dimensions,origin_slide.level_downsamples     #查看病理图片的金字塔结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_slide.level_count,mask_slide.level_dimensions,mask_slide.level_downsamples     #查看标注图片的金字塔结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先找到感兴趣区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 方法三：通过获取每一块区域的像素值R G B各自的平均数，然后相减，设置一个阈值，将噪点（墨迹）和有效区　分开\n",
    "\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "\n",
    "# 感兴趣区域锁定函数\n",
    "def locate_ROI(origin_slide,level=6):\n",
    "\n",
    "    origin_widths,origin_heights = origin_slide.dimensions\n",
    "\n",
    "    object_widths,object_heights = origin_slide.level_dimensions[level]\n",
    "\n",
    "    rgb_list_y = list()\n",
    "    rgb_list_x = list()\n",
    "    rgb_var_x = []\n",
    "    rgb_var_y = []\n",
    "    rgb_var_xi = []\n",
    "    rgb_var_yi = []\n",
    "\n",
    "    # 寻找有效区域的y值、高度\n",
    "    for k in range(100):\n",
    "        slide = origin_slide.read_region((0, k*origin_heights//100), level, (object_widths, object_heights//50)) \n",
    "        slide_arr = array(slide.convert(\"RGB\"))\n",
    "        arrR = np.mean(slide_arr[:,:,:1])\n",
    "        arrG = np.mean(slide_arr[:,:,1:2])\n",
    "        arrB = np.mean(slide_arr[:,:,2:3])\n",
    "        rgb_list_y.append((arrR,arrG,arrB))\n",
    "    for i,rgbVar in enumerate(rgb_list_y):\n",
    "        rgb_var_y.append(np.var(rgbVar))\n",
    "        if np.var(rgbVar)>=1:\n",
    "            rgb_var_yi.append(i)\n",
    "\n",
    "#     print(rgb_var_yi)\n",
    "    effective_y = min(rgb_var_yi)*origin_heights//100        #有效区域的左上顶点y坐标找到了\n",
    "    effective_heights = (max(rgb_var_yi)-min(rgb_var_yi))*origin_heights//100 + origin_heights//50  #有效区域的高度也出来了\n",
    "#     print(\"有效区域的ｙ值是：%d\" %effective_y, \"有效区域的高度是：%d\" %effective_heights)\n",
    "\n",
    "    # 寻找有效区域的x值、宽度\n",
    "    for j in range(100):\n",
    "        slide = origin_slide.read_region((j*origin_widths//100, effective_y), level, \n",
    "                                          (object_widths//50, effective_heights//62))     # 循环顺序读取50宽的区域\n",
    "    #     slide = origin_slide.read_region((j*origin_widths//100, 0), level, \n",
    "    #                                       (object_widths//50, object_heights))     # 循环顺序读取50宽的区域\n",
    "\n",
    "        slide_arr = array(slide.convert(\"RGB\"))\n",
    "        arrR = np.mean(slide_arr[:,:,:1])\n",
    "        arrG = np.mean(slide_arr[:,:,1:2])\n",
    "        arrB = np.mean(slide_arr[:,:,2:3])\n",
    "        rgb_list_x.append((arrR,arrG,arrB))\n",
    "    for i,rgbVar in enumerate(rgb_list_x):\n",
    "        rgb_var_x.append(np.var(rgbVar))\n",
    "        if np.var(rgbVar)>=2:\n",
    "            rgb_var_xi.append(i)\n",
    "\n",
    "#     print(rgb_var_xi)\n",
    "    effective_x = min(rgb_var_xi)*origin_widths//100        # 有效区域的左上顶点y坐标找到了\n",
    "    effective_widths = (max(rgb_var_xi) - min(rgb_var_xi))*origin_widths//100 + origin_widths//50  # 有效区域的宽度也出来了\n",
    "#     print(\"有效区域的ｘ值是：%d\" %effective_x, \"有效区域的宽度是：%d\" %effective_widths)\n",
    "#     plt.plot(range(100), rgb_var_y[:100], label='rgb_var_curve')\n",
    "    # plt.plot(range(100), rgb_var_x[:100], label='rgb_var_curve')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    return effective_x,effective_y,effective_widths,effective_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "effective_x,effective_y,effective_widths,effective_heights = locate_ROI(origin_slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18580, 125199, 41071, 50518)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_x,effective_y,effective_widths,effective_heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个有效区域，经过手动调试，起点坐标：(17600,124700) ，区域长宽：(44800,57600)\n",
    "\n",
    "\n",
    "\n",
    "### mask 的有效区域，定位比较容易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "\n",
    "def locate_ROI_mask(mask_slide,mask_level=7):\n",
    "\n",
    "    # level0　的尺寸\n",
    "    mask_widths, mask_heights = mask_slide.dimensions\n",
    "    # level7 的尺寸\n",
    "    mask_level_widths, mask_level_heights = mask_slide.level_dimensions[mask_level]\n",
    "\n",
    "    mask_level_slide = mask_slide.read_region((0, 0), mask_level, (mask_level_widths, mask_level_heights))\n",
    "    mask_level_slide_gray = mask_level_slide.convert(\"L\")\n",
    "    mask_level_slide_arr = array(mask_level_slide_gray)\n",
    "\n",
    "    mask_y, mask_x = nonzero(mask_level_slide_arr)  # 因为mask是黑白图，只需直接获得非零像素的坐标\n",
    "    # mask_x, mask_y\n",
    "    tumor_leftup_x = (min(mask_x)-1) * int(mask_slide.level_downsamples[mask_level])\n",
    "    tumor_leftup_y = (min(mask_y)-1) * int(mask_slide.level_downsamples[mask_level])\n",
    "    tumor_rightdown_x = (max(mask_x)+1) * int(mask_slide.level_downsamples[mask_level])\n",
    "    tumor_rightdown_y = (max(mask_y)+1) * int(mask_slide.level_downsamples[mask_level])\n",
    "    \n",
    "#     print(tumor_leftup_x,tumor_leftup_y,tumor_rightdown_x,tumor_rightdown_y)\n",
    "    mask_effective_widths = tumor_rightdown_x - tumor_leftup_x\n",
    "    mask_effective_heights = tumor_rightdown_y - tumor_leftup_y\n",
    "    \n",
    "#     mask_tumor_area = ((max(mask_x)-min(mask_x)+2)*int(mask_slide.level_downsamples[mask_level]), \n",
    "#                        (max(mask_y)-min(mask_y)+2)*int(mask_slide.level_downsamples[mask_level]))\n",
    "#     print(mask_tumor_area)        # mask区域的长宽\n",
    "    return tumor_leftup_x,tumor_leftup_y,mask_effective_widths,mask_effective_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tumor_leftup_x,tumor_leftup_y,mask_effective_widths,mask_effective_heights = locate_ROI_mask(mask_slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57600, 136320, 2048, 3712)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_leftup_x,tumor_leftup_y,mask_effective_widths,mask_effective_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask_slide.read_region((tumor_leftup_x,tumor_leftup_y),0,(mask_effective_widths,mask_effective_heights)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL.Image import Image\n",
    "from pylab import *\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 有效区域（感兴趣区域），所有细胞聚集区\n",
    "# effective_area = (effective_x, effective_y)\n",
    "# effective_area_size = (effective_widths, effective_heights)\n",
    "# 有效区域，所有标注的细胞聚集区\n",
    "# mask_slide.read_region(mask_tumor_start, 0, mask_tumor_area) \n",
    "# random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))  # 这一区域就是随机读到的区域，\n",
    "                                                            #接下来就要判断这个区域在哪里，应该给他贴上什么标签\n",
    "\n",
    "# 随机生成一个０到１之间的数，判断是否大于0.5,如果大于0.5,就从tumor区（mask）获取随机点（产生随机图片）；\n",
    "# 如果小于0.5,就从normal区获取随机点，产生的随机图片需要判断是否取到了tumor\n",
    "# for i in range(30):    # 这个其实就是 batch_size\n",
    "#     widths, heights = 299, 299\n",
    "def data_generator(widths=299,heights=299):\n",
    "    while True:\n",
    "        random_num = np.random.random(1)\n",
    "        print(\"0到１之间的随机数是：%s\"%random_num)\n",
    "\n",
    "        if random_num > 0.5:\n",
    "            # 定义随机坐标,一定要取到一张含有tumor的图片\n",
    "            random_x = np.random.randint(tumor_leftup_x, tumor_leftup_x + mask_effective_widths - widths)  \n",
    "            random_y = np.random.randint(tumor_leftup_y, tumor_leftup_y + mask_effective_heights - heights)\n",
    "    #             print(\"取tumor随机点坐标是：%d,%d\"%(random_x,random_y))\n",
    "            random_img_mask = mask_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "            random_img_mask_arr = array(random_img_mask.convert(\"L\"))\n",
    "            random__img_y, random_img_x = nonzero(random_img_mask_arr)\n",
    "            while len(random_img_x)==0:\n",
    "                random_x = np.random.randint(tumor_leftup_x, tumor_leftup_x + mask_effective_widths - widths)\n",
    "                random_y = np.random.randint(tumor_leftup_y, tumor_leftup_y + mask_effective_heights - heights)\n",
    "    #                 print(\"取tumor随机点坐标是：%d,%d\"%(random_x,random_y))\n",
    "                random_img_mask = mask_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "                random_img_mask_arr = array(random_img_mask.convert(\"L\"))\n",
    "                random__img_y, random_img_x = nonzero(random_img_mask_arr)\n",
    "\n",
    "            #*********************上面这个 while 循环结束后，就产生了一个合格的坐标点*********************#\n",
    "            random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "#             f,axes = plt.subplots(1,2)\n",
    "#             plt.subplot(1,2,1)\n",
    "#             plt.imshow(origin_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "#             plt.set_title('tumor_image')\n",
    "#             plt.subplot(1,2,2)\n",
    "#             plt.imshow(mask_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "#             plt.set_title('tumor_mask')\n",
    "#             plt.show()\n",
    "\n",
    "            #***接下来就给他贴标签，并处理成训练所需的数据结构***#\n",
    "            random_img_arr = array(random_img.convert(\"RGB\"))\n",
    "            x = np.expand_dims(random_img_arr, axis=0)/255.\n",
    "            y = to_categorical(0,2)    \n",
    "        else:\n",
    "            # 定义随机坐标，一定要取到一张不含有tumor的normal图片\n",
    "            random_x = np.random.randint(effective_x,effective_x+effective_widths-widths)   # 大图上,nomal有效区的起点和终点\n",
    "            random_y = np.random.randint(effective_y,effective_y+effective_heights-heights)\n",
    "    #             print(\"取normal随机点坐标是：%d,%d\"%(random_x,random_y))\n",
    "            random_img_mask = mask_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "            random_img_mask_arr = array(random_img_mask.convert(\"L\"))\n",
    "            random__img_y, random_img_x = nonzero(random_img_mask_arr)\n",
    "            random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "\n",
    "#             print(\"随机情况\",len(random_img_x),(array(random_img.convert(\"RGB\"))).std())\n",
    "\n",
    "            while (array(random_img.convert(\"RGB\"))).std()<20.0:\n",
    "                random_x = np.random.randint(effective_x,effective_x+effective_widths-widths)\n",
    "                random_y = np.random.randint(effective_y,effective_y+effective_heights-heights)\n",
    "    #                 print(\"取normal随机点坐标是：%d,%d\" %(random_x,random_y))\n",
    "                random_img_mask = mask_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "                random_img_mask_arr = array(random_img_mask.convert(\"L\"))\n",
    "                random__img_y, random_img_x = nonzero(random_img_mask_arr)\n",
    "                random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "\n",
    "#             print(\"颜色检测情况\",len(random_img_x),(array(random_img.convert(\"RGB\"))).std())\n",
    "\n",
    "            while len(random_img_x) != 0:\n",
    "                random_x = np.random.randint(effective_x,effective_x+effective_widths-widths)\n",
    "                random_y = np.random.randint(effective_y,effective_y+effective_heights-heights)\n",
    "    #                 print(\"取normal随机点坐标是：%d,%d\" %(random_x,random_y))\n",
    "                random_img_mask = mask_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "                random_img_mask_arr = array(random_img_mask.convert(\"L\"))\n",
    "                random__img_y, random_img_x = nonzero(random_img_mask_arr)\n",
    "                random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "\n",
    "#             print(\"非tumor区检测情况\",len(random_img_x), (array(random_img.convert(\"RGB\"))).std())\n",
    "\n",
    "            #*********************上面这个 while 循环结束后，就产生了一个合格的坐标点*********************#\n",
    "            random_img = origin_slide.read_region((random_x,random_y),0,(widths,heights))\n",
    "#             f,axes = plt.subplots(1,2)\n",
    "#             plt.subplot(1,2,1)\n",
    "#             plt.imshow(origin_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "#             plt.title('normal_image')\n",
    "#             plt.subplot(1,2,2)\n",
    "#             plt.imshow(mask_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "#             plt.title('normal_mask')\n",
    "#             plt.show()\n",
    "    #         f,axes = plt.subplots(1,2,figsize=(20,20))\n",
    "    #         ax = axes.ravel()\n",
    "    #         ax[0].imshow(origin_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "    #         ax[0].set_title('normal_image')\n",
    "    #         ax[1].imshow(mask_slide.read_region((random_x,random_y),0,(widths,heights)))\n",
    "    #         ax[1].set_title('normal_mask')\n",
    "    #         f\n",
    "            #***接下来就给他贴标签，并处理成训练所需的数据结构***#\n",
    "            random_img_arr = array(random_img.convert(\"RGB\"))\n",
    "            x = np.expand_dims(random_img_arr, axis=0)/255.\n",
    "            y = to_categorical(1,2) \n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0到１之间的随机数是：[ 0.79746816]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.7254902 ,  0.42745098,  0.58039216],\n",
       "          [ 0.74509804,  0.44705882,  0.59607843],\n",
       "          [ 0.6745098 ,  0.39215686,  0.5372549 ],\n",
       "          ..., \n",
       "          [ 0.25098039,  0.10980392,  0.25882353],\n",
       "          [ 0.23921569,  0.09803922,  0.24705882],\n",
       "          [ 0.25098039,  0.10980392,  0.25098039]],\n",
       " \n",
       "         [[ 0.77254902,  0.4745098 ,  0.62352941],\n",
       "          [ 0.7254902 ,  0.43529412,  0.58039216],\n",
       "          [ 0.61176471,  0.3372549 ,  0.48235294],\n",
       "          ..., \n",
       "          [ 0.21568627,  0.07843137,  0.24313725],\n",
       "          [ 0.19607843,  0.07058824,  0.23137255],\n",
       "          [ 0.20784314,  0.08235294,  0.23529412]],\n",
       " \n",
       "         [[ 0.80784314,  0.50980392,  0.65882353],\n",
       "          [ 0.70588235,  0.41568627,  0.56078431],\n",
       "          [ 0.54901961,  0.28235294,  0.42745098],\n",
       "          ..., \n",
       "          [ 0.18823529,  0.06666667,  0.23137255],\n",
       "          [ 0.17647059,  0.05490196,  0.21568627],\n",
       "          [ 0.19215686,  0.0745098 ,  0.22352941]],\n",
       " \n",
       "         ..., \n",
       "         [[ 0.39607843,  0.25882353,  0.38431373],\n",
       "          [ 0.46666667,  0.3254902 ,  0.43529412],\n",
       "          [ 0.55294118,  0.41176471,  0.51372549],\n",
       "          ..., \n",
       "          [ 0.22352941,  0.10980392,  0.29019608],\n",
       "          [ 0.21960784,  0.10588235,  0.28627451],\n",
       "          [ 0.25098039,  0.12941176,  0.30196078]],\n",
       " \n",
       "         [[ 0.29803922,  0.17647059,  0.30196078],\n",
       "          [ 0.34117647,  0.21176471,  0.33333333],\n",
       "          [ 0.38431373,  0.25490196,  0.36862745],\n",
       "          ..., \n",
       "          [ 0.20784314,  0.10196078,  0.27843137],\n",
       "          [ 0.19607843,  0.08627451,  0.2745098 ],\n",
       "          [ 0.20784314,  0.09411765,  0.2745098 ]],\n",
       " \n",
       "         [[ 0.23137255,  0.11372549,  0.24705882],\n",
       "          [ 0.24313725,  0.1254902 ,  0.25882353],\n",
       "          [ 0.25882353,  0.1372549 ,  0.27058824],\n",
       "          ..., \n",
       "          [ 0.2       ,  0.09803922,  0.2745098 ],\n",
       "          [ 0.18823529,  0.08627451,  0.2627451 ],\n",
       "          [ 0.18823529,  0.08235294,  0.25882353]]]]), array([[ 1.,  0.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.__next__() 　　　　# yield要用next调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0到１之间的随机数是：[ 0.54043864]\n",
      "CPU times: user 32.1 ms, sys: 15.9 ms, total: 48 ms\n",
      "Wall time: 48.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time example_X, example_y  = next(data_generator())    # yield要用next调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 299, 299, 3), (1, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_X.shape,example_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意这里的第一个数表示batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "接下来可以开始训练了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def Creat_InvepV3(num_lay_out=64,classes=2,dropout=0.5):\n",
    "    img_width, img_height = 299, 299\n",
    "    base_model = InceptionV3(weights=\"imagenet\", include_top=False,\n",
    "                             input_shape=(img_width, img_height, 3))\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(num_lay_out)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(classes)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer=SGD(lr=0.002, momentum=0.9, decay=0.5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def Creat_InvepV3(num_lay_out=1024,classes=2,dropout=0.5):\n",
    "    img_width, img_height = 299, 299\n",
    "    base_model = InceptionV3(weights=\"imagenet\", include_top=False,\n",
    "                             input_shape=(img_width, img_height, 3))\n",
    "    x = base_model.output\n",
    "    # x = Flatten()(x)\n",
    "    # x = Dense(num_lay_out)(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Activation('relu')(x)\n",
    "    # x = Dropout(dropout)(x)\n",
    "    # x = Dense(classes)(x)\n",
    "    # x = BatchNormalization()(x)\n",
    "    # x = Activation('softmax')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_lay_out, activation='relu')(x)\n",
    "    predictions = Dense(classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=SGD(lr=0.05, momentum=0.9, decay=0.5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0到１之间的随机数是：[ 0.97810762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\", line 606, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "ValueError: generator already executing\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a5b4f3736a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model0817.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a5b4f3736a6a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         callbacks=[csvlogger])\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model0817.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1850\u001b[0m                                          \u001b[0;34m'a tuple `(x, y, sample_weight)` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m                                          \u001b[0;34m'or `(x, y)`. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1853\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: None"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import keras\n",
    "from keras.callbacks import CSVLogger\n",
    "import gc\n",
    "\n",
    "def train_model():\n",
    "    keras.backend.tensorflow_backend.clear_session()\n",
    "    epochs = 100\n",
    "    model = Creat_InvepV3()\n",
    "    csvlogger = CSVLogger('training0817.log', append=True)\n",
    "    model.fit_generator(data_generator(),\n",
    "                        steps_per_epoch=100,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=data_generator(),\n",
    "                        validation_steps=20,\n",
    "                        verbose=0,\n",
    "                        workers=2,\n",
    "                        max_q_size=1,\n",
    "                        callbacks=[csvlogger])\n",
    "    model.save('model0817.h5')\n",
    "    gc.collect()\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
